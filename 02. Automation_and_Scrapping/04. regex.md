
```py
# Replacing text link with ading html tag
text = 'The link is gran.com. The price issol.com'
# Must have to wrapped with () round bracket.. here  " [\w]+ " a word "\." then adding Dot " [\w]+ " again a word
pattern = r'([\w]+\.[\w]+)'
# Here "\1" will replace the pattern
replacement = r'<a href="\1">\1</a>'
result = re.sub(pattern, replacement, text)
# Output: The link is <a href="gran.com">gran.com</a>. The price <a href="issol.com">issol.com</a>


text = "Additionally, there are.several job postings.available for Charge Solar in Canada on Indeed.com, indicating that they are an active and growing.company"
converted_text = re.sub(r'(\b(?:are|several))\.(\w+\b)(?!\.com)', r'\1. \2', linked_text)
print(converted_text)
# Output: Additionally, there are. several job postings.available for Charge Solar in Canada on Indeed.com, indicating that they are an active and growing.company 
"""
****(\b(?:are|several))\.(\w+\b)(?!\.com).
****(\b(?:are|several)) captures the words "are" or "several" as a group using a non-capturing group (?: ). The word boundary \b ensures that it matches the whole word and not a partial word.
****\. matches the dot character.
****(\w+\b) captures one or more word characters (letters, digits, or underscores) followed by a word boundary. This captures the word immediately after the dot.
****(?!\.com) is a negative lookahead assertion that ensures the pattern doesn't match if the dot is followed by ".com". The (?!\ ) construct is used to specify that the pattern inside the lookahead should not be present at that point.
In the replacement pattern r'\1. \2', the \1 represents the first captured group, which is "are" or "several". The dot and space are added between \1 and \2, which is the second captured group, representing the word immediately after the dot.
"""
```


### 01. Extract All Email Addresses
```py
import re

text = "Contact us at info@example.com or support@website.org for assistance."
emails = re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b', text)
print(emails)  # ['info@example.com', 'support@website.org']
```
### 02.Find All Hashtags in a Text
```py
text = "Loving the new #Python features! #coding #regex"
hashtags = re.findall(r'#\w+', text)
print(hashtags)  # ['#Python', '#coding', '#regex']
```
### 03. Remove HTML Tags
```py
text = "<p>This is a <strong>sample</strong> paragraph.</p>"
cleaned_text = re.sub(r'<.*?>', '', text)
print(cleaned_text)  # 'This is a sample paragraph.'
```

### 04. Replace Multiple Spaces with a Single Space
```py
text = "This    is  a   sentence    with   irregular   spacing."
normalized_text = re.sub(r'\s+', ' ', text)
print(normalized_text)  # 'This is a sentence with irregular spacing.'
```
### 05. Extract Dates in Format DD/MM/YYYY or DD-MM-YYYY
```py
text = "Important dates are 12/04/2021, 15-05-2022 and 30/06/2023."
dates = re.findall(r'\b\d{2}[-/]\d{2}[-/]\d{4}\b', text)
print(dates)  # ['12/04/2021', '15-05-2022', '30/06/2023']
```
### 06. Validate Phone Numbers (e.g., US Format (123) 456-7890 or 123-456-7890)
```py
phone_numbers = ["(123) 456-7890", "123-456-7890", "1234567890", "(123)456-7890"]
for number in phone_numbers:
    if re.match(r'(\(\d{3}\) |\d{3}-)\d{3}-\d{4}', number):
        print(f"{number} is a valid phone number")
```
### 07. Extract All Words Starting with a Capital Letter (Proper Nouns)
```py
text = "Alice went to Wonderland with Bob and Charlie."
proper_nouns = re.findall(r'\b[A-Z][a-z]*\b', text)
print(proper_nouns)  # ['Alice', 'Wonderland', 'Bob', 'Charlie']
```
### 08. Convert Snake Case to Camel Case
```py
text = "this_is_snake_case_text"
camel_case_text = re.sub(r'_([a-z])', lambda x: x.group(1).upper(), text)
print(camel_case_text)  # 'thisIsSnakeCaseText'
```
### 09. Replace Words with Synonyms
```py
text = "The quick brown fox jumps over the lazy dog."
synonyms = {"quick": "fast", "jumps": "leaps", "lazy": "idle"}
for word, synonym in synonyms.items():
    text = re.sub(fr'\b{word}\b', synonym, text)
print(text)  # 'The fast brown fox leaps over the idle dog.'
```
### 10. Extract URL Links from Text
```py
text = "Check out https://www.example.com and http://another-site.org for more info."
urls = re.findall(r'https?://[A-Za-z0-9.-]+(?:\.[A-Za-z]{2,})(?:/[\w.-]*)*', text)
print(urls)  # ['https://www.example.com', 'http://another-site.org']
```
### 11. Extract Product Prices (e.g., $10.99, USD 15, €9,99)
```py
text = "The product costs $10.99, another is EUR 15, and a third is priced at €9,99."
prices = re.findall(r'\b(?:\$|€|USD|EUR)?\s?\d+[.,]?\d*\b', text)
print(prices)  # ['$10.99', 'EUR 15', '€9,99']
```
### 12. Extract Measurements (e.g., 10kg, 5.5 liters, 3m)
```py
text = "The package weighs 10kg, the liquid is 5.5 liters, and the rope is 3m long."
measurements = re.findall(r'\b\d+(\.\d+)?\s?(kg|grams|liters|m|cm)\b', text)
print(measurements)  # [('10', 'kg'), ('5.5', 'liters'), ('3', 'm')]
```
### 13. Extract Time in 24-Hour or 12-Hour Formats
```py
text = "The meeting is at 14:30 and lunch is at 1:00 PM."
times = re.findall(r'\b(?:[01]?\d|2[0-3]):[0-5]\d(?:\s?[APMapm]{2})?\b', text)
print(times)  # ['14:30', '1:00 PM']
```
### 14. Extract Currency (e.g., $100, USD 200, €150, ¥500)
```py
text = "The item is worth $100 or €150, but in Japan, it might be ¥500."
currencies = re.findall(r'(\$|USD|€|EUR|¥|JPY)\s?\d+', text)
print(currencies)  # ['$100', '€150', '¥500']
```
### 15. Find Product Codes (e.g., ABC-1234, 123-ABC-456)
```py
text = "Our top products are ABC-1234 and 123-ABC-456."
product_codes = re.findall(r'\b[A-Za-z0-9]+-[A-Za-z0-9]+(?:-[A-Za-z0-9]+)?\b', text)
print(product_codes)  # ['ABC-1234', '123-ABC-456']
```
### 16. Extract Sentences with a Specific Word
```py
text = "This is a wonderful day. The weather is great. Today feels perfect."
sentences = re.findall(r'[^.]*\bwonderful\b[^.]*\.', text)
print(sentences)  # ['This is a wonderful day.']
```
### 17. Extract Dates in Different Formats (e.g., YYYY-MM-DD, DD/MM/YYYY, Month DD, YYYY)
```py
text = "Important dates are 2024-11-02, 02/11/2024, and November 2, 2024."
dates = re.findall(r'\b(?:\d{4}-\d{2}-\d{2}|\d{2}/\d{2}/\d{4}|[A-Za-z]+ \d{1,2}, \d{4})\b', text)
print(dates)  # ['2024-11-02', '02/11/2024', 'November 2, 2024']
```
### 18. Extract IP Addresses
```py
text = "Server 1: 192.168.1.1, Server 2: 10.0.0.1, Server 3: 172.16.0.1."
ip_addresses = re.findall(r'\b(?:\d{1,3}\.){3}\d{1,3}\b', text)
print(ip_addresses)  # ['192.168.1.1', '10.0.0.1', '172.16.0.1']
```
### 19. Extract Credit Card Numbers (e.g., 1234-5678-1234-5678 or 1234567812345678)
```py
text = "Your credit card number is 1234-5678-1234-5678 or 1234567812345678."
credit_cards = re.findall(r'\b(?:\d{4}-?){4}\b', text)
print(credit_cards)  # ['1234-5678-1234-5678', '1234567812345678']
```
### 20. Extract Discount Codes (e.g., SAVE10, DISCOUNT20)
```py
text = "Use discount codes SAVE10 or DISCOUNT20 at checkout!"
discount_codes = re.findall(r'\b[A-Z]+\d+\b', text)
print(discount_codes)  # ['SAVE10', 'DISCOUNT20']
```
### 21. Extract Hashtags with Words Following It
```py
text = "Loving the new #Python version! #coding in #JavaScript."
hashtags = re.findall(r'#\w+', text)
print(hashtags)  # ['#Python', '#coding', '#JavaScript']
```
### 22. Extract All Unique Words (Ignore Case)
```py
text = "Hello hello world! This world is beautiful."
unique_words = set(re.findall(r'\b\w+\b', text.lower()))
print(unique_words)  # {'hello', 'world', 'this', 'is', 'beautiful'}
```
### 23. Extract Hyphenated Words (e.g., well-known, high-quality)
```py
text = "She is well-known for her high-quality work."
hyphenated_words = re.findall(r'\b\w+-\w+\b', text)
print(hyphenated_words)  # ['well-known', 'high-quality']
```
### 24. Extract Abbreviations (e.g., NLP, AI, U.S.A.)
```py
text = "The fields of NLP, AI, and U.S.A. are fascinating."
abbreviations = re.findall(r'\b[A-Z]+(?:\.[A-Z]+)*\b', text)
print(abbreviations)  # ['NLP', 'AI', 'U.S.A.']
```
### 25. Extract Hexadecimal Color Codes (e.g., #FF5733, #0A0B0C)
```py
text = "Use color #FF5733 for the background and #0A0B0C for text."
hex_colors = re.findall(r'#[A-Fa-f0-9]{6}\b', text)
print(hex_colors)  # ['#FF5733', '#0A0B0C']
```
